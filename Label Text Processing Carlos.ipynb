{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Carlos Weffer\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\Carlos Weffer\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "c:\\Users\\Carlos Weffer\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"label_data/label_text_Adrian.csv\"\n",
    "df = pd.read_csv(file_path, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load pretrained models\n",
    "weight_pipe= pipeline(\"ner\", model=\"d4data/biomedical-ner-all\", aggregation_strategy=\"average\")\n",
    "food_pipe = pipeline(\"ner\", model=\"Dizex/InstaFoodRoBERTa-NER\", aggregation_strategy=\"max\")\n",
    "date_pipe = pipeline(\"ner\", model=\"mdarhri00/named-entity-recognition\", aggregation_strategy=\"average\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_extraction(text):\n",
    "\n",
    "    # Apply the pretrained models\n",
    "    lab_value_ents = weight_pipe(text, aggregation_strategy=\"average\")\n",
    "    date_ents = date_pipe(text)\n",
    "    food_ents = food_pipe(text)\n",
    "\n",
    "\n",
    "    food_name = \"No Food Found\"\n",
    "    packaged_date = \"No Package Date Found\"\n",
    "    expiry_date = \"No Expiry Date Found\"\n",
    "    weight = \"No Weight Found\"\n",
    "\n",
    "\n",
    "    # Getting Dates\n",
    "    #print(\"DATE ENT LIST:\")\n",
    "    for ent in date_ents:\n",
    "        if ent['entity_group'] == \"date_time\":\n",
    "            #print(f\"ent: {ent['word']}, class: {ent['entity_group']}\")\n",
    "            start = ent[\"start\"]\n",
    "            end = ent[\"end\"]\n",
    "            \n",
    "            # Get the tokens before and after the DATE entity\n",
    "            before_ent = text[start-20:start]\n",
    "            after_ent = text[end:end+5]\n",
    "            \n",
    "            # Check the context around the DATE entity\n",
    "            context = before_ent.lower() + \" \" + after_ent.lower()\n",
    "\n",
    "            # Define the phrases to look for\n",
    "            packaging_phrases = [\"packed\", \"pkg on\", \"packaged on\", 'production date']\n",
    "            expiry_phrases = [\"best before\", \"use by\", \"expiry date\", \"expires on\", \"expires by\", 'expires', 'after']\n",
    "\n",
    "            if any(phrase in context for phrase in expiry_phrases):\n",
    "                expiry_date = ent[\"word\"]\n",
    "            elif any(phrase in context for phrase in packaging_phrases):\n",
    "                packaged_date = ent[\"word\"]\n",
    "\n",
    "\n",
    "    # Getting Weight\n",
    "\n",
    "    # print(\"\")\n",
    "    #print(\"WEIGHT ENT LIST:\")\n",
    "    #[print(f\"ent: {ent['word']}, score: {ent['score']}, class: {ent['entity_group']}\") for ent in lab_value_ents]\n",
    "    weight_phrases = ['0g', '1g','2g','3g','4g','5g','6g','7g','8g', '9g', 'kg','grams','kilograms']\n",
    "    banned_weight_phrases = [\"-\", \"kg \", \"g \"]\n",
    "\n",
    "    weight_entities = [ent for ent in lab_value_ents if any(phrase in ent['word'].lower() for phrase in weight_phrases) and not any(phrase in ent['word'].lower() for phrase in banned_weight_phrases)]\n",
    "    #[print(f\"ent: {ent['word']}, score: {ent['score']}\") for ent in weight_entities]\n",
    "    max_score_entity = max(weight_entities, key=lambda entity: entity['score'])\n",
    "    weight = max_score_entity[\"word\"]\n",
    "\n",
    "\n",
    "    # Getting Food Name\n",
    "\n",
    "    # print(\"\")\n",
    "    # print(\"FOOD ENT LIST:\")\n",
    "    #[print(f\"ent: {ent['word']}, score: {ent['score']}\") for ent in food_ents]\n",
    "\n",
    "    max_score_entity = max(food_ents, key=lambda entity: entity['score'])\n",
    "    food_name = max_score_entity[\"word\"]\n",
    "\n",
    "\n",
    "    return expiry_date, packaged_date, weight, food_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Food Name:  Australia Beef Burger Bulk Pack\n",
      "Weight: 13. 63 kg\n",
      "Packaged Date: 14 May 2024\n",
      "Expiry Date: 14 May 2025\n",
      "\n",
      "Example Text: Keep Frozen Product of Australia Beef Burger Bulk Pack Net Wt 13.63 kg 13.63 KG Pkg On 14 May 2024 Best Before 14 May 2025 Top Cut Foods Pty Ltd 101265 Boneless Beef NL Allergens\n"
     ]
    }
   ],
   "source": [
    "text = df[0][1]\n",
    "\n",
    "expiry_date, packaged_date, weight, food_name = text_extraction(text)\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Food Name: {food_name}\")\n",
    "print(f\"Weight: {weight}\")\n",
    "print(f\"Packaged Date: {packaged_date}\")\n",
    "print(f\"Expiry Date: {expiry_date}\")\n",
    "print(\"\")\n",
    "print(f\"Example Text: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code which reads the results into a CSV file, saving here for later use\n",
    "\n",
    "\n",
    "# with open(\"label_data/label_text_Adrian.csv\", mode='r', encoding='utf-8') as file:\n",
    "#     csv_reader = csv.reader(file)\n",
    "#     with open(\"extracted_info.csv\", mode='w', newline='', encoding='utf-8') as output_file:\n",
    "#         csv_writer = csv.writer(output_file)\n",
    "#         csv_writer.writerow([\"Food Name\", \"Weight\", \"Expiry Date\"])\n",
    "#         for row in csv_reader:\n",
    "#             text = row[0]\n",
    "#             food_name, packaged_date, expiry_date = extract_information(text)\n",
    "#             csv_writer.writerow([food_name, packaged_date, expiry_date])\n",
    "\n",
    "# print(\"Information extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
